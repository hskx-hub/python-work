import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
from collections import Counter
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
import numpy as np
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import re
from sklearn.preprocessing import PolynomialFeatures

plt.rcParams['font.sans-serif'] = ['SimHei']  # ä¸­æ–‡å­—ä½“
plt.rcParams['axes.unicode_minus'] = False   # è´Ÿå·æ­£å¸¸æ˜¾ç¤º

# ===================== å¤§ä¹é€æ•°æ®å¤„ç† =====================

def fetch_dlt_before_july1(limit=200, save_path="dlt_before_july1.csv"):
    url = f"https://datachart.500.com/dlt/history/newinc/history.php?limit={limit}"
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Referer": "https://datachart.500.com/dlt/history.shtml",
        "Accept-Language": "zh-CN,zh;q=0.9"
    }
    try:
        print("ğŸ”„ æ­£åœ¨è¯·æ±‚å¤§ä¹é€å†å²æ•°æ®...")
        response = requests.get(url, headers=headers, timeout=20)
        response.encoding = "gb2312"
        soup = BeautifulSoup(response.text, "html.parser")
        rows = soup.select("tbody tr.t_tr1")

        data = []
        for row in rows:
            cols = row.find_all("td")
            if len(cols) >= 15:
                issue = cols[0].text.strip()
                reds = [cols[i].text.strip() for i in range(1, 6)]
                blues = [cols[6].text.strip(), cols[7].text.strip()]
                jackpot = cols[8].text.strip()
                first_prize_count = cols[9].text.strip()
                first_prize_money = cols[10].text.strip()
                second_prize_count = cols[11].text.strip()
                second_prize_money = cols[12].text.strip()
                total_sales = cols[13].text.strip().replace(',', '').replace('å…ƒ', '')
                draw_date = cols[14].text.strip()
                data.append([
                    issue, *reds, *blues, jackpot,
                    first_prize_count, first_prize_money,
                    second_prize_count, second_prize_money,
                    total_sales, draw_date
                ])

        columns = [
            "æœŸå·", "çº¢1", "çº¢2", "çº¢3", "çº¢4", "çº¢5",
            "è“1", "è“2", "å¥–æ± å¥–é‡‘(å…ƒ)",
            "ä¸€ç­‰å¥–æ³¨æ•°", "ä¸€ç­‰å¥–å¥–é‡‘(å…ƒ)",
            "äºŒç­‰å¥–æ³¨æ•°", "äºŒç­‰å¥–å¥–é‡‘(å…ƒ)",
            "æ€»æŠ•æ³¨é¢(å…ƒ)", "å¼€å¥–æ—¥æœŸ"
        ]
        df = pd.DataFrame(data, columns=columns)

        cutoff_date = datetime(2025, 7, 1)
        df["å¼€å¥–æ—¥æœŸ"] = pd.to_datetime(df["å¼€å¥–æ—¥æœŸ"], format="%Y-%m-%d", errors="coerce")
        df["æ€»æŠ•æ³¨é¢(å…ƒ)"] = pd.to_numeric(df["æ€»æŠ•æ³¨é¢(å…ƒ)"], errors="coerce")
        df = df[df["å¼€å¥–æ—¥æœŸ"] < cutoff_date]
        df = df.sort_values("å¼€å¥–æ—¥æœŸ", ascending=False).head(100)
        df.to_csv(save_path, index=False, encoding="utf-8-sig")
        print(f"âœ… æˆåŠŸä¿å­˜å¤§ä¹é€æ•°æ®åˆ° {save_path}")
        return df
    except Exception as e:
        print(f"âŒ æŠ“å–å¤§ä¹é€æ•°æ®å‡ºé”™ï¼š{e}")
        return None

def analyze_and_visualize(df):
    print("\nğŸ“Š å¼€å§‹åˆ†æå¤§ä¹é€æ•°æ®...")
    df = df.sort_values("å¼€å¥–æ—¥æœŸ")
    plt.figure(figsize=(10, 6))
    plt.plot(df["å¼€å¥–æ—¥æœŸ"], df["æ€»æŠ•æ³¨é¢(å…ƒ)"], marker='o')
    plt.title("å¤§ä¹é€æ€»é”€å”®é¢éšå¼€å¥–æ—¥æœŸå˜åŒ–")
    plt.xlabel("å¼€å¥–æ—¥æœŸ")
    plt.ylabel("æ€»é”€å”®é¢")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

    # æ·»åŠ æœŸæ•°åˆ—
    df["æœŸæ•°"] = np.arange(len(df))

    # è®¾ç½®ç‰¹å¾å’Œç›®æ ‡
    X = df[["æœŸæ•°"]]
    y = df["æ€»æŠ•æ³¨é¢(å…ƒ)"]

    # ç”Ÿæˆå¤šé¡¹å¼ç‰¹å¾ï¼ˆå¦‚ 2 æ¬¡æˆ– 3 æ¬¡ï¼‰
    poly = PolynomialFeatures(degree=2, include_bias=False)  # äºŒæ¬¡å¤šé¡¹å¼
    X_poly = poly.fit_transform(X)

    # æ‹Ÿåˆå¤šé¡¹å¼å›å½’æ¨¡å‹
    model = LinearRegression().fit(X_poly, y)

    # é¢„æµ‹ä¸‹ä¸€æœŸçš„æœŸæ•°
    next_period = np.array([[df["æœŸæ•°"].max() + 1]])
    next_period_poly = poly.transform(next_period)
    predicted_sales = model.predict(next_period_poly)

    print(f"ğŸ”® [å¤šé¡¹å¼å›å½’] é¢„æµ‹ä¸‹ä¸€æœŸæ€»é”€å”®é¢ï¼š{int(predicted_sales[0])} å…ƒ")

    front_numbers = []
    back_numbers = []
    for _, row in df.iterrows():
        front_numbers += [int(row[f"çº¢{i}"]) for i in range(1, 6)]
        back_numbers += [int(row["è“1"]), int(row["è“2"])]

    front_counts = Counter(front_numbers)
    plt.figure(figsize=(12, 5))
    plt.bar(front_counts.keys(), front_counts.values())
    plt.title("å‰åŒºå·ç å‡ºç°é¢‘ç‡")
    plt.xlabel("å·ç ")
    plt.ylabel("æ¬¡æ•°")
    plt.show()

    back_counts = Counter(back_numbers)
    plt.figure(figsize=(8, 4))
    plt.bar(back_counts.keys(), back_counts.values(), color='orange')
    plt.title("ååŒºå·ç å‡ºç°é¢‘ç‡")
    plt.xlabel("å·ç ")
    plt.ylabel("æ¬¡æ•°")
    plt.show()

    front_recommend = [num for num, _ in front_counts.most_common(5)]
    back_recommend = [num for num, _ in back_counts.most_common(2)]
    print(f"ğŸ¯ æ¨èæŠ•æ³¨å·ç ï¼šå‰åŒº {front_recommend}ï¼ŒååŒº {back_recommend}")

def analyze_draw_days(df):
    print("\nğŸ“… åˆ†æå¼€å¥–æ—¥æ¨¡å¼...")

    df["æ˜ŸæœŸ"] = df["å¼€å¥–æ—¥æœŸ"].dt.dayofweek
    df["æ˜ŸæœŸä¸­æ–‡"] = df["æ˜ŸæœŸ"].map({0: "å‘¨ä¸€", 2: "å‘¨ä¸‰", 5: "å‘¨å…­"})
    filtered = df[df["æ˜ŸæœŸ"].isin([0, 2, 5])]
    grouped = filtered.groupby("æ˜ŸæœŸä¸­æ–‡")

    all_front_counts = {}
    sales_stats = {}

    for name, group in grouped:
        print(f"\n{name}ï¼šå¼€å¥–æ¬¡æ•° {len(group)}ï¼Œå¹³å‡æŠ•æ³¨é¢ï¼š{int(group['æ€»æŠ•æ³¨é¢(å…ƒ)'].mean())} å…ƒ")

        nums = []
        for _, row in group.iterrows():
            nums += [int(row[f"çº¢{i}"]) for i in range(1, 6)]
        counts = Counter(nums)
        all_front_counts[name] = counts
        sales_stats[name] = {
            "å¹³å‡é”€å”®é¢": group["æ€»æŠ•æ³¨é¢(å…ƒ)"].mean(),
            "é”€å”®é¢æ ‡å‡†å·®": group["æ€»æŠ•æ³¨é¢(å…ƒ)"].std()
        }

        plt.figure(figsize=(8, 4))
        plt.bar(counts.keys(), counts.values())
        plt.title(f"{name} å‰åŒºå·ç åˆ†å¸ƒ")
        plt.xlabel("å·ç ")
        plt.ylabel("é¢‘ç‡")
        plt.show()

    print("\nğŸ“Š ä¸åŒå¼€å¥–æ—¥å·ç åˆ†å¸ƒå¯¹æ¯”ï¼ˆå‰åŒºï¼‰")
    all_keys = sorted(set(k for d in all_front_counts.values() for k in d))
    width = 0.25
    plt.figure(figsize=(12, 6))
    for i, (name, counts) in enumerate(all_front_counts.items()):
        values = [counts.get(k, 0) for k in all_keys]
        plt.bar([x + i * width for x in range(len(all_keys))], values, width=width, label=name)
    plt.xticks([x + width for x in range(len(all_keys))], all_keys)
    plt.legend()
    plt.title("ä¸åŒå¼€å¥–æ—¥çš„å‰åŒºå·ç åˆ†å¸ƒå¯¹æ¯”")
    plt.xlabel("å·ç ")
    plt.ylabel("é¢‘ç‡")
    plt.tight_layout()
    plt.show()

    print("\nğŸ“Š ä¸åŒå¼€å¥–æ—¥æ€»é”€å”®é¢å¯¹æ¯”æŸ±çŠ¶å›¾")
    plt.figure(figsize=(8, 5))
    sns.barplot(x=list(sales_stats.keys()), y=[v["å¹³å‡é”€å”®é¢"] for v in sales_stats.values()], palette="Set2")
    plt.title("ä¸åŒå¼€å¥–æ—¥å¹³å‡é”€å”®é¢")
    plt.xlabel("æ˜ŸæœŸ")
    plt.ylabel("å¹³å‡é”€å”®é¢")
    plt.show()

    print("\nğŸ”µ ååŒºå·ç åˆ†å¸ƒå¯¹æ¯”ï¼ˆæŒ‰å¼€å¥–æ—¥ï¼‰")
    all_back_counts = {}
    for name, group in grouped:
        back_nums = []
        for _, row in group.iterrows():
            back_nums += [int(row["è“1"]), int(row["è“2"])]
        counts = Counter(back_nums)
        all_back_counts[name] = counts

    all_back_keys = sorted(set(k for d in all_back_counts.values() for k in d))
    plt.figure(figsize=(10, 5))
    for i, (name, counts) in enumerate(all_back_counts.items()):
        values = [counts.get(k, 0) for k in all_back_keys]
        plt.bar([x + i * width for x in range(len(all_back_keys))], values, width=width, label=name)
    plt.xticks([x + width for x in range(len(all_back_keys))], all_back_keys)
    plt.legend()
    plt.title("ä¸åŒå¼€å¥–æ—¥ååŒºå·ç åˆ†å¸ƒå¯¹æ¯”")
    plt.xlabel("å·ç ")
    plt.ylabel("é¢‘ç‡")
    plt.tight_layout()
    plt.show()

# ===================== ä¸“å®¶æ•°æ®å¤„ç† =====================

def extract_number(text):
    if not isinstance(text, str):
        return None
    m = re.search(r'\d+', text)
    return int(m.group()) if m else None

def fetch_expert_from_cmzj(limit=20):
    url = "https://i.cmzj.net/expert/hotExpertList?lottery=2"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        print("ğŸ”„ æ­£åœ¨è·å–ä¸“å®¶æ•°æ®...")
        res = requests.get(url, headers=headers)
        data = res.json().get("data", [])

        experts = []
        for exp in data[:limit]:
            expert_id = exp.get("expertId")
            detail = get_expert_info(expert_id)

            if detail:
                experts.append({
                    "ä¸“å®¶ID": expert_id,
                    "å§“å": detail.get("name"),
                    "å½©é¾„": detail.get("cai_ling"),
                    "æ–‡ç« æ•°é‡": detail.get("articles"),
                    "åŒè‰²çƒä¸€ç­‰å¥–": detail.get("åŒè‰²çƒä¸€ç­‰å¥–"),
                    "åŒè‰²çƒäºŒç­‰å¥–": detail.get("åŒè‰²çƒäºŒç­‰å¥–"),
                    "åŒè‰²çƒä¸‰ç­‰å¥–": detail.get("åŒè‰²çƒä¸‰ç­‰å¥–"),
                    "å¤§ä¹é€ä¸€ç­‰å¥–": detail.get("å¤§ä¹é€ä¸€ç­‰å¥–"),
                    "å¤§ä¹é€äºŒç­‰å¥–": detail.get("å¤§ä¹é€äºŒç­‰å¥–"),
                    "å¤§ä¹é€ä¸‰ç­‰å¥–": detail.get("å¤§ä¹é€ä¸‰ç­‰å¥–"),
                })

        df = pd.DataFrame(experts)
        df.to_csv("expert_list.csv", index=False, encoding="utf-8-sig")
        print("âœ… ä¸“å®¶æ•°æ®ä¿å­˜å®Œæ¯•")
        return df
    except Exception as e:
        print(f"âŒ æŠ“å–ä¸“å®¶æ•°æ®å¤±è´¥ï¼š{e}")
        return None



import requests


def get_expert_info(expert_id):
    url = f"https://i.cmzj.net/expert/queryExpertById?expertId={expert_id}"
    try:
        resp = requests.get(url, timeout=10)
        resp.raise_for_status()
        data = resp.json()

        if data.get("code") == 0 and data.get("data"):
            expert = data["data"]
            return {
                "name": expert.get("name"),
                "grade": expert.get("gradeName"),
                "cai_ling": expert.get("age"),
                "articles": expert.get("articles"),
                "åŒè‰²çƒä¸€ç­‰å¥–": expert.get("ssqOne", 0),
                "åŒè‰²çƒäºŒç­‰å¥–": expert.get("ssqTwo", 0),
                "åŒè‰²çƒä¸‰ç­‰å¥–": expert.get("ssqThree", 0),
                "å¤§ä¹é€ä¸€ç­‰å¥–": expert.get("dltOne", 0),
                "å¤§ä¹é€äºŒç­‰å¥–": expert.get("dltTwo", 0),
                "å¤§ä¹é€ä¸‰ç­‰å¥–": expert.get("dltThree", 0)
            }
        else:
            print(f"æ¥å£è¿”å›é”™è¯¯æˆ–æ— æ•°æ®: {data.get('msg')}")
            return None
    except Exception as e:
        print(f"è¯·æ±‚å¤±è´¥: {e}")
        return None

def analyze_expert_data(df):
    print("\nğŸ“Š å¼€å§‹åˆ†æä¸“å®¶æ•°æ®...")

    # ç±»å‹è½¬æ¢
    for col in ["å½©é¾„", "æ–‡ç« æ•°é‡", "åŒè‰²çƒä¸€ç­‰å¥–", "åŒè‰²çƒäºŒç­‰å¥–", "åŒè‰²çƒä¸‰ç­‰å¥–",
                "å¤§ä¹é€ä¸€ç­‰å¥–", "å¤§ä¹é€äºŒç­‰å¥–", "å¤§ä¹é€ä¸‰ç­‰å¥–"]:
        df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)

    df["åŒè‰²çƒæ€»å¥–"] = df["åŒè‰²çƒä¸€ç­‰å¥–"] + df["åŒè‰²çƒäºŒç­‰å¥–"] + df["åŒè‰²çƒä¸‰ç­‰å¥–"]
    df["å¤§ä¹é€æ€»å¥–"] = df["å¤§ä¹é€ä¸€ç­‰å¥–"] + df["å¤§ä¹é€äºŒç­‰å¥–"] + df["å¤§ä¹é€ä¸‰ç­‰å¥–"]
    df["æ€»ä¸­å¥–æ•°"] = df["åŒè‰²çƒæ€»å¥–"] + df["å¤§ä¹é€æ€»å¥–"]

    # ========== 1. å½©é¾„ vs å‘æ–‡é‡ ==========
    plt.figure(figsize=(8, 6))
    sns.scatterplot(data=df, x="å½©é¾„", y="æ–‡ç« æ•°é‡", size="æ€»ä¸­å¥–æ•°", hue="æ€»ä¸­å¥–æ•°", palette="viridis", sizes=(20, 200))
    plt.title("å½©é¾„ vs æ–‡ç« æ•°é‡ï¼ˆæ°”æ³¡å¤§å°=æ€»ä¸­å¥–æ•°ï¼‰")
    plt.xlabel("å½©é¾„ï¼ˆå¹´ï¼‰")
    plt.ylabel("æ–‡ç« æ•°é‡")
    plt.legend()
    plt.tight_layout()
    plt.show()

    # ========== 2. å½©é¾„ä¸ä¸­å¥–æ•°å…³ç³» ==========
    plt.figure(figsize=(10, 5))
    sns.regplot(data=df, x="å½©é¾„", y="æ€»ä¸­å¥–æ•°", scatter_kws={'s': 60})
    plt.title("å½©é¾„å¯¹ä¸­å¥–æ€»æ•°çš„å½±å“")
    plt.xlabel("å½©é¾„ï¼ˆå¹´ï¼‰")
    plt.ylabel("æ€»ä¸­å¥–æ•°")
    plt.tight_layout()
    plt.show()

    # ========== 3. å‘æ–‡é‡ä¸ä¸­å¥–æ€»æ•° ==========
    plt.figure(figsize=(10, 5))
    sns.regplot(data=df, x="æ–‡ç« æ•°é‡", y="æ€»ä¸­å¥–æ•°", scatter_kws={'s': 60}, color='orange')
    plt.title("å‘æ–‡é‡å¯¹ä¸­å¥–æ€»æ•°çš„å½±å“")
    plt.xlabel("æ–‡ç« æ•°é‡")
    plt.ylabel("æ€»ä¸­å¥–æ•°")
    plt.tight_layout()
    plt.show()

    # ========== 4. èšç±»åˆ†æ ==========
    print("\nğŸ¤– æ­£åœ¨è¿›è¡Œä¸“å®¶èšç±»åˆ†æï¼ˆKMeansï¼‰...")
    features = df[["å½©é¾„", "æ–‡ç« æ•°é‡", "æ€»ä¸­å¥–æ•°"]]
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(features)

    kmeans = KMeans(n_clusters=3, random_state=42)
    df["èšç±»æ ‡ç­¾"] = kmeans.fit_predict(X_scaled)

    plt.figure(figsize=(10, 6))
    sns.scatterplot(data=df, x="å½©é¾„", y="æ–‡ç« æ•°é‡", hue="èšç±»æ ‡ç­¾", size="æ€»ä¸­å¥–æ•°", palette="Set1", sizes=(50, 250))
    plt.title("ä¸“å®¶èšç±»åˆ†å¸ƒï¼ˆåŸºäºå½©é¾„ã€æ–‡ç« ã€ä¸­å¥–ï¼‰")
    plt.tight_layout()
    plt.show()

    # ========== 5. PCA é™ç»´å¯è§†åŒ– ==========
    print("ğŸ§¬ ä½¿ç”¨PCAå¯¹ä¸“å®¶è¿›è¡ŒäºŒç»´å¯è§†åŒ–...")
    pca = PCA(n_components=2)
    components = pca.fit_transform(X_scaled)
    df["PCA1"] = components[:, 0]
    df["PCA2"] = components[:, 1]

    plt.figure(figsize=(10, 6))
    sns.scatterplot(data=df, x="PCA1", y="PCA2", hue="èšç±»æ ‡ç­¾", style="èšç±»æ ‡ç­¾", s=100)
    for i in range(len(df)):
        plt.text(df["PCA1"][i]+0.1, df["PCA2"][i], df["å§“å"][i], fontsize=9)
    plt.title("ä¸“å®¶èšç±»ï¼ˆPCAé™ç»´å¯è§†åŒ–ï¼‰")
    plt.tight_layout()
    plt.show()

    # ========== 6. æ’åå‰å‡ çš„ä¸“å®¶ ==========
    top_experts = df.sort_values("æ€»ä¸­å¥–æ•°", ascending=False).head(5)
    print("\nğŸ† ä¸­å¥–æœ€å¤šçš„å‰5ä½ä¸“å®¶ï¼š")
    print(top_experts[["å§“å", "å½©é¾„", "æ–‡ç« æ•°é‡", "æ€»ä¸­å¥–æ•°"]])

# ===================== ä¸»ç¨‹åºå…¥å£ =====================

if __name__ == "__main__":
    # å¤§ä¹é€æ•°æ®å¤„ç†ä¸åˆ†æ
    df_dlt = fetch_dlt_before_july1()
    if df_dlt is not None:
        analyze_and_visualize(df_dlt)
        analyze_draw_days(df_dlt)

    # ä¸“å®¶æ•°æ®æŠ“å–ä¸åˆ†æ
    df_expert = fetch_expert_from_cmzj()
    if df_expert is not None:
        analyze_expert_data(df_expert)


